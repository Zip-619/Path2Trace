{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pickle\n",
    "from torch.nn.utils.rnn import pad_sequence,pad_packed_sequence\n",
    "import torch \n",
    "import sys\n",
    "import numpy as np\n",
    "from utils import load_file\n",
    "import os\n",
    "from itertools import combinations\n",
    "sys.path.append('../data/pengpai/')\n",
    "from address import address\n",
    "HEAD = 0\n",
    "TAIL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    with open('old2new_case_id.pickle','rb') as file:\n",
    "        old2new_case_id = pickle.load(file)\n",
    "        file.close()\n",
    "    with open('spread_net.pickle','rb') as file:\n",
    "        spread_net = pickle.load(file)\n",
    "        file.close()\n",
    "\n",
    "    reindexed_sp_net = nx.Graph()\n",
    "    for edge in spread_net.edges():\n",
    "        reindexed_sp_net.add_edge(old2new_case_id[edge[HEAD]],old2new_case_id[edge[TAIL]])\n",
    "    with open('../data/pengpai/labeled_data/case_path.pickle','rb') as file:\n",
    "        case_path = pickle.load(file)\n",
    "        file.close()\n",
    "    return old2new_case_id,spread_net,old2new_case_id,reindexed_sp_net,case_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter(list1,list2):\n",
    "    return list(set(list1)&set(list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def association_analysis_full(caseid_1,caseid_2):\n",
    "    try:\n",
    "        path1 = [addr.get_addr('full') for addr in case_path[old2new_case_id.inv[caseid_1]]]\n",
    "        path2 = [addr.get_addr('full') for addr in case_path[old2new_case_id.inv[caseid_2]]]\n",
    "        inter_path = inter(path1,path2)\n",
    "    except KeyError:\n",
    "        return False\n",
    "    if inter_path:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(caseid,case_path,old2new_case_id):\n",
    "    path = []\n",
    "    for addr in case_path[old2new_case_id.inv[caseid]]:\n",
    "        path.append(addr.get_addr('full'))\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def association_analysis_no_province(caseid_1,caseid_2):\n",
    "    path1,path2 = [],[]\n",
    "    try:\n",
    "        path1 = get_path(caseid_1)\n",
    "        path2 = get_path(caseid_2)\n",
    "        inter_path = inter(path1,path2)\n",
    "    except KeyError:\n",
    "        return False\n",
    "    if inter_path:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics_analysis(reindexed_sp_net):\n",
    "\n",
    "    accurancy,precision,recall = {},{},{}\n",
    "    # for i in range(0,20):\n",
    "    #     ratio = i/10.0\n",
    "    all_pair = load_file(f'dataset/case_idx_pair/test_dataloader_4_random.pickle').dataset\n",
    "\n",
    "    correct,wrong = 0,0\n",
    "    TP,TN,FP,FN = 0.0,0.0,0.0,0.0\n",
    "    for pair in all_pair:\n",
    "        # if type=='full':\n",
    "        association_analysis = association_analysis_full(pair[HEAD],pair[TAIL])\n",
    "        # if type=='no province':\n",
    "        #     association_analysis = association_analysis_no_province(pair[HEAD],pair[TAIL])\n",
    "        if association_analysis==True:\n",
    "            if reindexed_sp_net.has_edge(pair[HEAD],pair[TAIL]) == True:\n",
    "                TP+=1\n",
    "            if reindexed_sp_net.has_edge(pair[HEAD],pair[TAIL]) ==False:\n",
    "                FP+=1\n",
    "        else:\n",
    "            if reindexed_sp_net.has_edge(pair[HEAD],pair[TAIL]) ==True:\n",
    "                FN+=1\n",
    "            if reindexed_sp_net.has_edge(pair[HEAD],pair[TAIL]) ==False:\n",
    "                TN+=1\n",
    "\n",
    "    accurancy = (TN+TP)/(TP+TN+FP+FN)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "    print('TP:%d\\tFP:%d\\tFN:%d\\tTN:%d\\taccurancy:%.4f\\tprecision:%.4f\\trecall:%.4f\\tf1:%.4f  ' % (TP,FP,FN,TN,accurancy,precision,recall,f1))\n",
    "    return accurancy,precision,recall,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataloader.dataloader'; 'dataloader' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_68904/1729930540.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"__main__\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[0mold2new_case_id\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mspread_net\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mold2new_case_id\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mreindexed_sp_net\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mcase_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m     \u001B[0mstatistics_analysis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreindexed_sp_net\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;31m#     statistics_analysis(reindexed_sp_net,'same_province')\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;31m#     statistics_analysis(reindexed_sp_net,'same_city')\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_68904/2192608715.py\u001B[0m in \u001B[0;36mstatistics_analysis\u001B[1;34m(reindexed_sp_net)\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[1;31m# for i in range(0,20):\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[1;31m#     ratio = i/10.0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m     \u001B[0mall_pair\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf'dataset/case_idx_pair/test_dataloader_4_random.pickle'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m     \u001B[1;31m# with open('ratio_analysis/all_idx_pair'+str(ratio)+'.pickle','rb') as file:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[1;31m#     all_pair = pickle.load(file)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\PycharmProjects\\Case_Association_Prediction_opensource\\link_prediction\\utils.py\u001B[0m in \u001B[0;36mload_file\u001B[1;34m(file_path)\u001B[0m\n\u001B[0;32m    220\u001B[0m     \"\"\"\n\u001B[0;32m    221\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'rb'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 222\u001B[1;33m         \u001B[0mcase_paths\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpickle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    223\u001B[0m         \u001B[0mfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    224\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mcase_paths\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'dataloader.dataloader'; 'dataloader' is not a package"
     ]
    }
   ],
   "source": [
    "old2new_case_id,spread_net,old2new_case_id,reindexed_sp_net,case_path = load_data()\n",
    "statistics_analysis(reindexed_sp_net)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}